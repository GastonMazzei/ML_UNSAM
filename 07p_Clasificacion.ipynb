{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "07p_Clasificacion.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "NR_k-irK5_D1",
        "xWea29HBWC-Z"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGs9_54T5oeh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "cmap = matplotlib.cm.get_cmap('Spectral')\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.linear_model import Perceptron, LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NR_k-irK5_D1",
        "colab_type": "text"
      },
      "source": [
        "# Clasificacion\n",
        "\n",
        "Vamos a hacer una introduccion a problemas de clasificacion adelantandonos nuevamente. Veamos como seria resolver un problema de clasificacion ingenuo con ayuda de sklearn en datos reales."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1vpGO_w_Ul1",
        "colab_type": "text"
      },
      "source": [
        "# El problema:\n",
        "\n",
        "En esta cuarentena, estoy muy metido en la NBA. Con mi grupo de adictos, empezamos a charlar para matar el tiempo y me surgio una pregunta. ~Puedo hablar de basquet en vez de trabajar?~ Puedo mentir con seguridad sobre las estadisticas que leo en los articulos?\n",
        "\n",
        "Para eso, me puse a explorar un poco. En primer lugar, necesito datos. Para eso, recurro a una pagina llamada basketballreference.com donde se almacenan todos los datos posibles. Para hacer las cosas mas simples, me voy a limitar a una unica temporada, en la que los roles posicionales son mas o menos los mismos en la liga (salvo en Houston) y no tengo jugadores repetidos (salvo los que fueron transferidos, pero ahora mismo no me interesa ser demasiado cauto en el procesado)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbPWuJSJ6hnV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from urllib.request import urlopen\n",
        "from bs4 import BeautifulSoup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xyf7cjI9m_q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BeautifulSoup?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jg115KYe6yxo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = \"https://www.basketball-reference.com/leagues/NBA_{}_advanced.html\".format(2016)# this is the HTML from the given URL\n",
        "html = urlopen(url)\n",
        "soup = BeautifulSoup(html)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOnwq08d9Zae",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "soup.findAll('tr', limit=2)# use getText()to extract the text we need into a list\n",
        "headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]# exclude the first column as we will not need the ranking order from Basketball Reference for the analysis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMDLxLDW9grs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "headers = headers[1:]\n",
        "rows = soup.findAll('tr')[1:]\n",
        "player_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "stats = pd.DataFrame(player_stats, columns = headers)\n",
        "stats=stats.drop('\\xa0',axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1m4oZ9yM958c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stats.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bPzGq6jW9y4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stats[stats['Tm']=='TOT']['Player']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dQPVsTuiWPf",
        "colab_type": "text"
      },
      "source": [
        "En particular, todo a partir de OWS son estadisticas que me hablan de \"cuan bueno es un jugador\", y estan obtenidas con ciertas combinaciones de las previas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lm471WZNU880",
        "colab_type": "text"
      },
      "source": [
        "En particular, yo me quiero plantear el siguiente problema. Que tan bien tienen que jugar los jugadores para clasificar a Playoffs? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAWxwgbeWYVz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "teams=stats['Tm'].unique()\n",
        "teams"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9QFsgHkWQsd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "no_playoff_west=np.asarray(['SAC','DEN','LAL','MIN','PHO','UTA','NOP'])\n",
        "print(len(no_playoff_west))\n",
        "playoff_west=np.asarray(['GSW','SAS','OKC','LAC','POR','DAL','MEM','HOU'])\n",
        "print(len(playoff_west))\n",
        "\n",
        "no_playoff_east=np.asarray(['CHI','WAS','ORL','MIL','NYK','BRK','PHI'])\n",
        "print(len(no_playoff_east))\n",
        "playoff_east=np.asarray(['CLE','TOR','MIA','ATL','BOS','CHO','IND','DET'])\n",
        "print(len(playoff_east))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVqHfn2oAb8a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stats['Pos'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jxee2t6hAC89",
        "colab_type": "text"
      },
      "source": [
        "# El procesado\n",
        "\n",
        "En principio, yo tengo mi dataframe y ahora lo unico que voy a hacer es separar en Train y Test y luego asignarles las clases. En particular, voy considerar jugadores que jugaron cierta cantidad de los partidos al menos cierta cantidad de minutos y que participaron mucho del partido."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruTCss2k-37Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stats_now=stats.copy()\n",
        "stats_now=stats_now[stats_now['Pos'].isin(['SG','PF','PG','C','SF'])]\n",
        "stats_now[\"G\"]=pd.to_numeric(stats_now[\"G\"])\n",
        "stats_now[\"MP\"]=pd.to_numeric(stats_now[\"MP\"])\n",
        "stats_now[\"USG%\"]=pd.to_numeric(stats_now[\"USG%\"])\n",
        "#stats_now=stats_now[stats_now[\"USG%\"]>stats_now[\"USG%\"].mean()]\n",
        "stats_now[\"MPperG\"]=stats_now[\"MP\"]/stats_now[\"G\"]\n",
        "#stats_now=stats_now[stats_now[\"G\"]>=40]\n",
        "#stats_now=stats_now[stats_now[\"MPperG\"]>=25]\n",
        "stats_now=stats_now[stats_now[\"Tm\"]!=\"TOT\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBu5O4nGEyVP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stats_now=stats_now.replace(['PG','SG','SF','PF','C'],[1,2,3,4,5])\n",
        "stats_now['Pos'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7znYxQfRdbnm",
        "colab_type": "text"
      },
      "source": [
        "Generemos los labels. Voy a aplicar el siguiente codigo:\n",
        "\n",
        "0: no playoff oeste\n",
        "1: playoff oeste\n",
        "2: no playoff este\n",
        "3: playoff este"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWpbO1A-d5BS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stats_now['label']=stats_now[\"Tm\"]\n",
        "stats_now['label']=stats_now['label'].replace(no_playoff_west,0)\n",
        "stats_now['label']=stats_now['label'].replace(playoff_west,1)\n",
        "stats_now['label']=stats_now['label'].replace(no_playoff_east,2)\n",
        "stats_now['label']=stats_now['label'].replace(playoff_east,3)\n",
        "print(stats_now['label'].value_counts())\n",
        "#print(stats_now['Tm'].value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pOz3M7xZ_EF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stats_now.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdC0OCh3apwC",
        "colab_type": "text"
      },
      "source": [
        "Bien, ahora definamos las caracteristicas que voy a utilizar. Para visualizar facilmente voy a elegir unicamente dos: PER y USG%. Guardo ademas el nombre, la posicion y el label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaKzOo7iapQX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stats_now=stats_now[['Player','Pos','PER','USG%','label']]\n",
        "stats_now['PER']=pd.to_numeric(stats_now['PER'])\n",
        "stats_now['USG%']=pd.to_numeric(stats_now['USG%'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldI41Gzeqfl2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(stats_now.iloc[np.where(stats_now[\"Player\"]==\"LeBron James\")])\n",
        "print(stats_now.iloc[np.where(stats_now[\"Player\"]==\"Will Barton\")])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETnfPfXtUvZQ",
        "colab_type": "text"
      },
      "source": [
        "Veamos si hay jugadores repetidos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USICzbaRAqPV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(stats_now['Player'].value_counts())\n",
        "plt.hist(stats_now['Player'].value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lL0wBLSTUzHf",
        "colab_type": "text"
      },
      "source": [
        "Los hay pero son pocos por lo que no me voy a gastar en corregirlo.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XZ4SKpalD2r",
        "colab_type": "text"
      },
      "source": [
        "Dividamos en train y test. Como cada posicion es un mundo, voy a estratificar para que train y test tengan mismas proporciones de cada posicio\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2128Xh5BViN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=445543)\n",
        "for train_index, test_index in split.split(stats_now, stats_now[\"Pos\"]):\n",
        "    strat_train_set = stats_now.iloc[train_index]\n",
        "    strat_test_set = stats_now.iloc[test_index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Db0ehNgVC0JI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stats_train = strat_train_set.drop([\"Player\",\"Pos\",\"label\"], axis=1) # drop labels for training set\n",
        "stats_train_labels = strat_train_set[\"label\"].copy()\n",
        "stats_test = strat_test_set.drop([\"Player\",\"Pos\",\"label\"], axis=1) # drop labels for training set\n",
        "stats_test_labels = strat_test_set[\"label\"].copy()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lICJfuGkVE-_",
        "colab_type": "text"
      },
      "source": [
        "Veamos cuantos datos tengo para interpolar:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTGq55HYgBkf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(stats_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5r2d8ZbtiU1Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.hist(stats_train['PER'],bins=10)\n",
        "plt.xlabel(r'PER')\n",
        "plt.show()\n",
        "plt.hist(stats_train['USG%'],bins=10)\n",
        "plt.xlabel(r'USG%')\n",
        "plt.show()\n",
        "plt.scatter(stats_train['PER'][stats_train_labels==0],stats_train['USG%'][stats_train_labels==0], c='red', label=\"No Playoff Oeste\")\n",
        "plt.scatter(stats_train['PER'][stats_train_labels==1],stats_train['USG%'][stats_train_labels==1], c='blue', label=\"Playoff Oeste\")\n",
        "plt.legend(loc='upper left',framealpha =0.1)\n",
        "plt.xlim(9.0,31.0)\n",
        "plt.ylim(15.0,35.0)\n",
        "plt.xlabel(r'PER')\n",
        "plt.ylabel('USG%')\n",
        "plt.show()\n",
        "plt.scatter(stats_train['PER'][stats_train_labels==2],stats_train['USG%'][stats_train_labels==2], c='orange', label=\"No Playoff Este\")\n",
        "plt.scatter(stats_train['PER'][stats_train_labels==3],stats_train['USG%'][stats_train_labels==3], c='green', label=\"Playoff Este\")\n",
        "plt.legend(loc='upper left',framealpha =0.1)\n",
        "plt.xlabel(r'PER')\n",
        "plt.ylabel('USG%')\n",
        "plt.xlim(9.0,31.0)\n",
        "plt.ylim(15.0,35.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9KJ_P2JtG96",
        "colab_type": "text"
      },
      "source": [
        "En el Oeste, esperaria tener muy pocos falsos positivos pero una gran cantidad de falsos negativos. En el Este pasa lo mismo pero menos pronunciado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhCM-NQrrVNP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(strat_train_set[strat_train_set[\"PER\"]<12.0])\n",
        "print(strat_train_set[strat_train_set[\"PER\"]>25.0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWqUwnXPVsbz",
        "colab_type": "text"
      },
      "source": [
        "#Clasificacion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8MWf7Lhr2CR",
        "colab_type": "text"
      },
      "source": [
        "Entrenemos un clasificador, para Este y Oeste separados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICTEjXVYuZ1S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_este=np.asarray(strat_train_set[(stats_train_labels==2) | (stats_train_labels==3)][[\"PER\",\"USG%\"]])\n",
        "print(X_este.shape)\n",
        "y_este=np.asarray(strat_train_set[(stats_train_labels==2) | (stats_train_labels==3)][[\"label\"]])\n",
        "y_este=np.where(y_este==2,0,1)[:,0]\n",
        "print(y_este.shape)\n",
        "\n",
        "X_oeste=np.asarray(strat_train_set[(stats_train_labels==0) | (stats_train_labels==1)][[\"PER\",\"USG%\"]])\n",
        "print(X_oeste.shape)\n",
        "y_oeste=np.asarray(strat_train_set[(stats_train_labels==0) | (stats_train_labels==1)][[\"label\"]])\n",
        "print(y_oeste.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLNHI2DRQi6f",
        "colab_type": "text"
      },
      "source": [
        "El primer algoritmo importante que vamos a ver es Discriminante Lineal de Fisher. El objetivo del algoritmo, que es ademas un ejemplo de reduccion dimensional, es encontrar las componentes que minimizen la varianza intraclase y maximizen la varianza entre clases.\n",
        "\n",
        "Para el caso de 2 clases, el discriminante lineal de fisher busca encontrar los coeficientes $w$ tales que la funcion discriminante es\n",
        "\n",
        "$y=w_{0}+\\vec{w}^{T}\\cdot \\vec{x}$\n",
        "\n",
        "Y la superficie de decision usual es $y=0$. $w_{0}$ es el `intercept_` y $\\vec{w}$ el vector de `coef_`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcwgnwLAS0HT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LDA_este=LinearDiscriminantAnalysis(solver='eigen')\n",
        "LDA_este.fit(X_este,y_este)\n",
        "print(LDA_este.intercept_,LDA_este.coef_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-SydSdETMMH",
        "colab_type": "text"
      },
      "source": [
        "Grafiquemos un poco los valores posibles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rjqu6YQeTQgj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=np.linspace(9.0,31.0,100)\n",
        "y=np.linspace(15.0,35.0,100)\n",
        "Xtoplot,Ytoplot=np.meshgrid(x,y)\n",
        "plt.xlim(9.0,31.0)\n",
        "plt.ylim(15.0,35.0)\n",
        "Z=LDA_este.intercept_ + LDA_este.coef_[0,0]*Xtoplot+LDA_este.coef_[0,1]*Ytoplot\n",
        "plt.contourf(Xtoplot,Ytoplot,Z,levels=[-2.0,-1.0,0.0,1.0,2.0,2.5],alpha=0.6)\n",
        "plt.colorbar()\n",
        "plt.scatter(stats_train['PER'][stats_train_labels==2],stats_train['USG%'][stats_train_labels==2], c='orange', label=\"No Playoff Este\")\n",
        "plt.scatter(stats_train['PER'][stats_train_labels==3],stats_train['USG%'][stats_train_labels==3], c='green', label=\"Playoff Este\")\n",
        "plt.legend(loc='upper left',framealpha =0.1)\n",
        "plt.xlabel(r'PER')\n",
        "plt.ylabel('USG%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQeNaFNUT-V-",
        "colab_type": "text"
      },
      "source": [
        "Otra manera de obtener la funcion de decision es usando... `decision_function`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26W4vE4LUK4m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=np.linspace(9.0,31.0,100)\n",
        "y=np.linspace(15.0,35.0,100)\n",
        "Xtoplot,Ytoplot=np.meshgrid(x,y)\n",
        "plt.xlim(9.0,31.0)\n",
        "plt.ylim(15.0,35.0)\n",
        "Z=LDA_este.decision_function(np.c_[Xtoplot.ravel(), Ytoplot.ravel()]).reshape(Xtoplot.shape)\n",
        "plt.contourf(Xtoplot,Ytoplot,Z,levels=[-2.0,-1.0,0.0,1.0,2.0,2.5],alpha=0.6)\n",
        "plt.colorbar()\n",
        "plt.scatter(stats_train['PER'][stats_train_labels==2],stats_train['USG%'][stats_train_labels==2], c='orange', label=\"No Playoff Este\")\n",
        "plt.scatter(stats_train['PER'][stats_train_labels==3],stats_train['USG%'][stats_train_labels==3], c='green', label=\"Playoff Este\")\n",
        "plt.legend(loc='upper left',framealpha =0.1)\n",
        "plt.xlabel(r'PER')\n",
        "plt.ylabel('USG%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NNaqYJTUT6U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LDA_este.decision_function(X_este[0,:].reshape(1,-1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGob1PHnU-GD",
        "colab_type": "text"
      },
      "source": [
        "Podemos asignar las clases utilizando la funcion de decision. sklearn nos lo provee con `predict` donde el umbral esta en $y=0$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDdmpQ0OVM8W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=np.linspace(9.0,31.0,100)\n",
        "y=np.linspace(15.0,35.0,100)\n",
        "Xtoplot,Ytoplot=np.meshgrid(x,y)\n",
        "plt.xlim(9.0,31.0)\n",
        "plt.ylim(15.0,35.0)\n",
        "Z=LDA_este.predict(np.c_[Xtoplot.ravel(), Ytoplot.ravel()]).reshape(Xtoplot.shape)\n",
        "plt.contourf(Xtoplot,Ytoplot,Z,levels=[0.0,0.5,1.0],colors=['orange','green'],alpha=0.6)\n",
        "plt.scatter(stats_train['PER'][stats_train_labels==2],stats_train['USG%'][stats_train_labels==2], c='orange', label=\"No Playoff Este\")\n",
        "plt.scatter(stats_train['PER'][stats_train_labels==3],stats_train['USG%'][stats_train_labels==3], c='green', label=\"Playoff Este\")\n",
        "plt.legend(loc='upper left',framealpha =0.1)\n",
        "plt.xlabel(r'PER')\n",
        "plt.ylabel('USG%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5H8_GDa8VeQI",
        "colab_type": "text"
      },
      "source": [
        "Una vez asignamos las clases, podemos calcular matriz de confusion y con eso distintas metricas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ODzpgxsVknQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cf_este=confusion_matrix(y_este,LDA_este.predict(X_este))\n",
        "print(cf_este)\n",
        "tn, fp, fn, tp = cf_este.ravel()\n",
        "print(\"Sensitividad (TPR/Recall):%8.3f\" % (tp/(tp+fn)))\n",
        "print(\"Especificidad:%8.3f\" % (tn/(tn+fp)))\n",
        "print(\"Precision:%8.3f\" % (tp/(tp+fp)))\n",
        "print(\"FPR:%8.3f\" % (fp/(tn+fp)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGiT92gEVxfG",
        "colab_type": "text"
      },
      "source": [
        "De todas maneras, no tenemos demasiados datos pero podemos ver que lo mas alto es la especificidad. Es decir, no solemos asignar como positivos a los verdaderos negativos. Lo peor que tenemos es la sensitividad, que nos dice cuantos positivos nos perdemos. La precision nos dice cuan seguros podemos estar de un positivo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIIzw3K8Wj4i",
        "colab_type": "text"
      },
      "source": [
        "El segundo algoritmo es el Perceptron Multicapa, que tambien obtiene una funcion discriminante. \n",
        "\n",
        "$y=f(\\vec{w}^{T}\\cdot\\vec{\\phi}(\\vec{x}))$\n",
        "\n",
        "Con $f(a)=\\frac{a}{|a|}a$ y por convencion $\\phi_0(\\vec{x})=1$.\n",
        "\n",
        "El Perceptron se resuelve con algoritmo iterativo que solo tiene asegurada la convergencia para problemas linealmente separables, que no es el caso. Sin embargo, ya que estamos probemoslo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsGOikptX-HU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Percep_este=LinearDiscriminantAnalysis(solver='eigen')\n",
        "Percep_este.fit(X_este,y_este)\n",
        "print(Percep_este.intercept_,Percep_este.coef_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIJb258BYKqL",
        "colab_type": "text"
      },
      "source": [
        "Como es un algoritmo que busca la funcion discriminante, se puede hacer lo mismo que hicimos para LDA."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOZJeUFBQwMr",
        "colab_type": "text"
      },
      "source": [
        "El tercero es el de Regresion Logistica. A diferencia de los anteriores, este es un algoritmo que, bajo ciertas hipotesis, busca recuperar el posterior de la clase. Es decir, obtiene una probabilidad para cada clase. \n",
        "\n",
        "$y_{k}(\\vec{w},\\vec{x})=p(k|\\vec{w},\\vec{x})$\n",
        "\n",
        "\n",
        "Es un ejemplo de un algoritmo discriminativo. En principio, se necesitan tantas funciones $y$ como clases. Sin embargo, el caso de 2 clases provee una simplificacion ya que como son probabilidades, $y_{0}+y_{1} = 1$. Entonces, llamo $y$ a $y_{1}$ y puedo escribir de manera compacta.\n",
        "\n",
        "$t=0,1$\n",
        "\n",
        "$p(t|\\vec{x},\\vec{w})=y(\\vec{x},\\vec{w})^{t}(1-y(\\vec{x},\\vec{w}))^{1-t}$\n",
        "\n",
        "$y(\\vec{w},\\vec{x})=\\sigma(\\vec{w}^{T}\\cdot\\vec{\\phi}(\\vec{x}))$\n",
        "\n",
        "Donde $\\sigma$ es la funcion sigmoide.\n",
        "\n",
        "Ahora la superficie de decision estara, para dos clases, en la recta de equiprobabilidad \n",
        "\n",
        "$p(0|\\vec{w},\\vec{x})=p(1|\\vec{w},\\vec{x})$\n",
        "\n",
        "$1-y=y$\n",
        "\n",
        "$y=0.5$\n",
        "\n",
        "El error que se minimiza en este caso no es el de cuadrados minimos sino que es el de la entropia cruzada (_cross-entropy_):\n",
        "\n",
        "\n",
        "$E(\\vec{w})=-\\sum_{n=1}^{N}(t_{n}\\text{ln}(y_{n})+(1-t_{n})\\text{ln}(1-y_{n}))$\n",
        "\n",
        "Ya no se puede minimizar esto analiticamente pero se puede hacer de manera numerica."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPb0luRFwvIC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logistic_este=LogisticRegression()\n",
        "logistic_este.fit(X_este,y_este)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkMHpksJagAw",
        "colab_type": "text"
      },
      "source": [
        "Ahora, ademas de funcion de decision, tenemos probabilidaes:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fu32fLasakVQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "proba=logistic_este.predict_proba(X_este)\n",
        "print(proba.shape)\n",
        "print(proba[0],y_este[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1abWWkp2bGxa",
        "colab_type": "text"
      },
      "source": [
        "Y tambien tenemos la opcion predict, tal como antes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQUR7N67w7gX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=np.linspace(9.0,31.0,100)\n",
        "y=np.linspace(15.0,35.0,100)\n",
        "Xtoplot,Ytoplot=np.meshgrid(x,y)\n",
        "plt.xlim(9.0,31.0)\n",
        "plt.ylim(15.0,35.0)\n",
        "Z=logistic_este.predict(np.c_[Xtoplot.ravel(), Ytoplot.ravel()]).reshape(Xtoplot.shape)\n",
        "plt.contourf(Xtoplot,Ytoplot,Z,levels=[0.0,0.5,1.0],colors=['orange','green'],alpha=0.6)\n",
        "plt.scatter(stats_train['PER'][stats_train_labels==2],stats_train['USG%'][stats_train_labels==2], c='orange', label=\"No Playoff Este\")\n",
        "plt.scatter(stats_train['PER'][stats_train_labels==3],stats_train['USG%'][stats_train_labels==3], c='green', label=\"Playoff Este\")\n",
        "plt.legend(loc='upper left',framealpha =0.1)\n",
        "plt.xlabel(r'PER')\n",
        "plt.ylabel('USG%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIZw9yg9-Sxz",
        "colab_type": "text"
      },
      "source": [
        "Podemos sacar mas informacion viendo la matriz de confusion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENB4CAH29xvp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cf_este=confusion_matrix(y_este,logistic_este.predict(X_este))\n",
        "print(cf_este)\n",
        "tn, fp, fn, tp = cf_este.ravel()\n",
        "print(\"Sensitividad (TPR/Recall):%8.3f\" % (tp/(tp+fn)))\n",
        "print(\"Especificidad:%8.3f\" % (tn/(tn+fp)))\n",
        "print(\"Precision:%8.3f\" % (tp/(tp+fp)))\n",
        "print(\"FPR:%8.3f\" % (fp/(tn+fp)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7NKFiXWbPRt",
        "colab_type": "text"
      },
      "source": [
        "Ya que tenemos probabilidades, yo me siento comodo jugando un poco con los umbrales de decision:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgeqDKyBdaic",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=np.linspace(9.0,31.0,100)\n",
        "y=np.linspace(15.0,35.0,100)\n",
        "Xtoplot,Ytoplot=np.meshgrid(x,y)\n",
        "plt.xlim(9.0,31.0)\n",
        "plt.ylim(15.0,35.0)\n",
        "Z=logistic_este.predict_proba(np.c_[Xtoplot.ravel(), Ytoplot.ravel()])[:,1].reshape(Xtoplot.shape)\n",
        "plt.contourf(Xtoplot,Ytoplot,Z,levels=[0.0,0.2,0.4,0.5,0.6,0.8,1.0],alpha=0.6)\n",
        "plt.colorbar()\n",
        "plt.scatter(stats_train['PER'][stats_train_labels==2],stats_train['USG%'][stats_train_labels==2], c='orange', label=\"No Playoff Este\")\n",
        "plt.scatter(stats_train['PER'][stats_train_labels==3],stats_train['USG%'][stats_train_labels==3], c='green', label=\"Playoff Este\")\n",
        "plt.legend(loc='upper left',framealpha =0.1)\n",
        "plt.xlabel(r'PER')\n",
        "plt.ylabel('USG%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBRdr9T8b4yW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "fpr, tpr, thresholds = roc_curve(y_este, logistic_este.predict_proba(X_este)[:,1])\n",
        "\n",
        "plt.figure(figsize=(8, 6))                         # Not shown\n",
        "plt.plot(fpr, tpr, linewidth=2, label=None)\n",
        "plt.plot([0, 1], [0, 1], 'k--') # dashed diagonal\n",
        "plt.axis([0, 1, 0, 1])\n",
        "plt.scatter(fpr[np.argmin(np.abs(thresholds-0.5))],tpr[np.argmin(np.abs(thresholds-0.5))],color='red')                                    # Not shown in the book\n",
        "plt.xlabel('False Positive Rate (Fall-Out)', fontsize=16) # Not shown\n",
        "plt.ylabel('True Positive Rate (Recall)', fontsize=16)    # Not shown\n",
        "plt.grid(True)                                            # Not shown\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmWev-_qTEK8",
        "colab_type": "text"
      },
      "source": [
        "## Y si quiero mas inputs?\n",
        "\n",
        "Bueno, en principio puedo elegir mas inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4KHUyJKTMwh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stats_now=stats_now[['Player','Pos','PER','USG%','TS%','3PAr','FTr','ORB%','DRB%','TRB%','AST%','STL%','BLK%','TOV%','label']]\n",
        "for e in ['PER','USG%','TS%','3PAr','FTr','ORB%','DRB%','TRB%','AST%','STL%','BLK%','TOV%']:\n",
        "  stats_now[e]=pd.to_numeric(stats_now[e])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfqI1QvmUO3U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=445543)\n",
        "for train_index, test_index in split.split(stats_now, stats_now[\"Pos\"]):\n",
        "    strat_train_set = stats_now.iloc[train_index]\n",
        "    strat_test_set = stats_now.iloc[test_index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHl3IEovUVlT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stats_train = strat_train_set.drop([\"Player\",\"Pos\",\"label\"], axis=1) # drop labels for training set\n",
        "stats_train_labels = strat_train_set[\"label\"].copy()\n",
        "stats_test = strat_test_set.drop([\"Player\",\"Pos\",\"label\"], axis=1) # drop labels for training set\n",
        "stats_test_labels = strat_test_set[\"label\"].copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNIYP2CAUhNV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_este=np.asarray(stats_train[(stats_train_labels==2) | (stats_train_labels==3)])\n",
        "print(X_este.shape)\n",
        "y_este=np.asarray(strat_train_set[(stats_train_labels==2) | (stats_train_labels==3)][[\"label\"]])\n",
        "y_este=np.where(y_este==2,0,1)[:,0]\n",
        "print(y_este.shape)\n",
        "\n",
        "X_oeste=np.asarray(stats_train[(stats_train_labels==0) | (stats_train_labels==1)])\n",
        "print(X_oeste.shape)\n",
        "y_oeste=np.asarray(strat_train_set[(stats_train_labels==0) | (stats_train_labels==1)][[\"label\"]])\n",
        "print(y_oeste.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlvAQykrUszb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaler=StandardScaler()\n",
        "X_este_tr=scaler.fit_transform(X_este)\n",
        "LDA_este_multi=LinearDiscriminantAnalysis(solver='eigen')\n",
        "LDA_este_multi.fit(X_este_tr,y_este)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-xt6FazVAtu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cf_este=confusion_matrix(y_este,LDA_este_multi.predict(X_este_tr))\n",
        "print(cf_este)\n",
        "tn, fp, fn, tp = cf_este.ravel()\n",
        "print(\"Sensitividad:%8.3f\" % (tp/(tp+fn)))\n",
        "print(\"Especificidad:%8.3f\" % (tn/(tn+fp)))\n",
        "print(\"Precision:%8.3f\" % (tp/(tp+fp)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBRsbrXmVKY1",
        "colab_type": "text"
      },
      "source": [
        "Funciona mejor! Pero para plottear, hay que marginalizar en las otras variables.\n",
        "\n",
        "Una alternativa es utilizar herramientas de reduccion de dimensionalidad. LDA es una de ellas, que baja de 12 features a 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUyRDVjrV_pW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LDA_este_multi.decision_function(X_este_tr).shape\n",
        "plt.hist(LDA_este_multi.decision_function(X_este_tr[y_este==0]),color='orange',histtype='step',label='No playoff este')\n",
        "plt.hist(LDA_este_multi.decision_function(X_este_tr[y_este==1]),color='green',histtype='step',label='Playoff este')\n",
        "plt.axvline(x=0,color='black',label='Frontera de decision')\n",
        "plt.legend(loc='upper left',framealpha=0.6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKXq2722WqBd",
        "colab_type": "text"
      },
      "source": [
        "Una alternativa es usar Principal Component analysis (PCA) para bajar de 12 a 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4m-rHniW4ad",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=2)\n",
        "X_este_pca=pca.fit_transform(X_este)\n",
        "X_este_pca.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmmG0_v5XR8d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.hist(X_este_pca[:,0],bins=10)\n",
        "plt.xlabel(r'PCA 1')\n",
        "plt.show()\n",
        "plt.hist(X_este_pca[:,1],bins=10)\n",
        "plt.xlabel(r'PCA 2')\n",
        "plt.show()\n",
        "plt.scatter(X_este_pca[y_este==0,0],X_este_pca[y_este==0,1], c='orange', label=\"No Playoff Este\")\n",
        "plt.scatter(X_este_pca[y_este==1,0],X_este_pca[y_este==1,1], c='green', label=\"Playoff Oeste\")\n",
        "plt.legend(loc='upper left',framealpha =0.1)\n",
        "#plt.xlim(9.0,31.0)\n",
        "#plt.ylim(15.0,35.0)\n",
        "plt.xlabel(r'PCA 1')\n",
        "plt.ylabel('PCA 2')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5uhC1pzX6ST",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LDA_este_pca=LinearDiscriminantAnalysis(solver='eigen')\n",
        "LDA_este_pca.fit(X_este_pca,y_este)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLq0VqDqYbVv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=np.linspace(-25.0,25.0,100)\n",
        "y=np.linspace(-15.0,15.0,100)\n",
        "Xtoplot,Ytoplot=np.meshgrid(x,y)\n",
        "plt.xlim(-25.0,25.0)\n",
        "plt.ylim(-15.0,15.0)\n",
        "Z=LDA_este_pca.predict(np.c_[Xtoplot.ravel(), Ytoplot.ravel()]).reshape(Xtoplot.shape)\n",
        "plt.contourf(Xtoplot,Ytoplot,Z,levels=[0.0,0.5,1.0],colors=['orange','green'],alpha=0.6)\n",
        "plt.scatter(X_este_pca[y_este==0,0],X_este_pca[y_este==0,1], c='orange', label=\"No Playoff Este\")\n",
        "plt.scatter(X_este_pca[y_este==1,0],X_este_pca[y_este==1,1], c='green', label=\"Playoff Oeste\")\n",
        "plt.legend(loc='upper left',framealpha =0.1)\n",
        "plt.xlabel(r'PCA 1')\n",
        "plt.ylabel('PCA 2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23gEi-TqX-V-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cf_este=confusion_matrix(y_este,LDA_este_pca.predict(X_este_pca))\n",
        "print(cf_este)\n",
        "tn, fp, fn, tp = cf_este.ravel()\n",
        "print(\"Sensitividad (TPR/Recall) :%8.3f\" % (tp/(tp+fn)))\n",
        "print(\"Especificidad:%8.3f\" % (tn/(tn+fp)))\n",
        "print(\"Precision:%8.3f\" % (tp/(tp+fp)))\n",
        "print(\"FPR :%8.3f\" % (fp/(tn+fp)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcAkknsXeoYs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "minmax=MinMaxScaler()\n",
        "print(LDA_este_pca.decision_function(X_este_pca).min(),LDA_este_pca.decision_function(X_este_pca).max())\n",
        "decision=minmax.fit_transform(LDA_este_pca.decision_function(X_este_pca).reshape(-1,1))\n",
        "print(decision.min(),decision.max())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SFXsZ9QebBy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "fpr, tpr, thresholds = roc_curve(y_este, LDA_este_pca.decision_function(X_este_pca))\n",
        "print(thresholds[0],thresholds[-1])\n",
        "plt.figure(figsize=(8, 6))                         # Not shown\n",
        "plt.plot(fpr, tpr, linewidth=2, label=None)\n",
        "plt.plot([0, 1], [0, 1], 'k--') # dashed diagonal\n",
        "plt.axis([0, 1, 0, 1])\n",
        "plt.scatter(fpr[np.argmin(np.abs(thresholds-0.0))],tpr[np.argmin(np.abs(thresholds-0.0))],color='red')                                    # Not shown in the book\n",
        "plt.xlabel('False Positive Rate (Fall-Out)', fontsize=16) # Not shown\n",
        "plt.ylabel('True Positive Rate (Recall)', fontsize=16)    # Not shown\n",
        "plt.grid(True)                                            # Not shown\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWea29HBWC-Z",
        "colab_type": "text"
      },
      "source": [
        "# Test"
      ]
    }
  ]
}