{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02p_Probabilidad_e_Inferencia.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "PAsu1RWg6yZn"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vM1er7re4ZRz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preparamos todo para correr\n",
        "import numpy as np\n",
        "from math import sqrt\n",
        "from matplotlib import pylab as plt\n",
        "from scipy.stats import norm\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YHHk9_85PR6",
        "colab_type": "text"
      },
      "source": [
        "# Probabilidad Condicionada y Teorema de Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8RooE0C5UQ3",
        "colab_type": "text"
      },
      "source": [
        "Apliquemos los conceptos vistos con Rodrigo en el siguiente problema:\n",
        "\n",
        "__Ejercicio__: \n",
        "\n",
        "Una enfermedad genética rara afecta al 0.1% de la población de un país. Para diagnosticarla, existe un análisis clínico que detecta la enfermedad en el 99% de los casos en los que el paciente la padece, y tiene un 1% de falsos positivos.\n",
        "\n",
        "Un paciente recibe un resultado positivo del análisis clínico.\n",
        "\n",
        "¿Qué probabilidad hay de que la persona padezca la enfermedad?\n",
        "¿Cuál sería el próximo paso natural?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65eUeQF65x7g",
        "colab_type": "text"
      },
      "source": [
        "Antes de avanzar, entendamos bien el problema.\n",
        "\n",
        "__Cual es el espacio de muestreo?__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtpXLc0cxKOO",
        "colab_type": "text"
      },
      "source": [
        "$S = (E,\\bar{E})\\cdot(D,\\bar{D})$\n",
        "\n",
        "$S = (ED,E\\bar{D},\\bar{E}D.\\bar{E}\\bar{D})$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udyYuV8p5SHb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKIiTJFY6GNn",
        "colab_type": "text"
      },
      "source": [
        "__Que es un falso positivo?__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FKKjhh9yqsp",
        "colab_type": "text"
      },
      "source": [
        "Falso Positivo: Paciente sano, test positivo $\\rightarrow$ $\\bar{E}D$ "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvkLx-Pe6fVb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pE=0.001\n",
        "pDE=0.99\n",
        "pDnE=0.01"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwDOx2mF6ike",
        "colab_type": "text"
      },
      "source": [
        "__Escribamos las probabilidades que podemos inferir del enunciado__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5Y-RS2azDRS",
        "colab_type": "text"
      },
      "source": [
        "Queremos $P(E | D)$\n",
        "\n",
        "Sabemos que:\n",
        "\n",
        "1.   $P(E) = 0.001$\n",
        "2.   $P(D|E) = 0.99$\n",
        "3.   $P(D|\\bar{E}) = 0.01 $\n",
        "\n",
        "$P(E|I) + P(\\bar{E}|I) = 1 $\n",
        "\n",
        "$P(D|I) + P(\\bar{D}|I) = 1 $\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sjrb9q9N6m6Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCPrnjnw6nyj",
        "colab_type": "text"
      },
      "source": [
        "Ahora si, resolvamos el problema. \n",
        "\n",
        "__Que queremos obtener? Como podemos obtenerlo a partir de los datos?__ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCUR_p-80N_4",
        "colab_type": "text"
      },
      "source": [
        "__Teorema de Bayes__:\n",
        "\n",
        "$P(E|D)=\\frac{P(D|E)P(E)}{P(D)}$\n",
        "\n",
        "__Prior:__ $P(E)$\n",
        "__Verosimilitud:__ $P(D|E)$\n",
        "__Evidencia:__ $P(D)$\n",
        "__Posterior:__ $P(E|D)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64zQ-v1p02fm",
        "colab_type": "text"
      },
      "source": [
        "__Regla de la Suma:__\n",
        "\n",
        "$P(D) = P(D|E)p(E) + P(D|\\bar{E})p(\\bar{E})$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFsYff_T6w40",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "230404ce-2985-4d88-adfb-0782708ebdef"
      },
      "source": [
        "pD=pDE*pE+pDnE*(1-pE)\n",
        "print(\"Probabilidad total de un test positivo: \", pD)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Probabilidad total de un test positivo:  0.01098\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qr5lXAHy1c_u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fdc272cd-5fe3-43ae-f911-ecd17d6936d6"
      },
      "source": [
        "pED=pDE*pE/pD\n",
        "print(\"Probabilidad de estar enfermo dado que dio un test positivo: \", pED)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Probabilidad de estar enfermo dado que dio un test positivo:  0.09016393442622951\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9lnPSp02ALo",
        "colab_type": "text"
      },
      "source": [
        "__Falso positivo:__\n",
        "\n",
        "$P(\\bar{E}|D)=1-P(E|D)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LObFuO_B2Wv0",
        "colab_type": "text"
      },
      "source": [
        "__Testear una segunda calcular:__\n",
        "\n",
        "$P(E|D_{1}D_{2})=\\frac{P(D_{1}D_{2}|E)P(E)}{p(D_{1}D_{2})}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4aCeCRS2yKu",
        "colab_type": "text"
      },
      "source": [
        "Utilizo indepndencia de los test:\n",
        "\n",
        "$p(D_{1}D_{2}|E)=p(D_{2}|D_{1}E)p(D_{1}|E)$\n",
        "\n",
        "Como $p(D_{2}|D_{1}E)=p(D_{2}|E)$\n",
        "\n",
        "$p(D_{1}D_{2}|E)=p(D|E)^2$\n",
        "\n",
        "$P(D_{1}D_{2})=p(D|E)^{2}p(E)+p(D|\\bar{E})^{2}p(\\bar{E})$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbiXTrdG3p_D",
        "colab_type": "text"
      },
      "source": [
        "__Actualizacion Bayesiana:__\n",
        "\n",
        "$P(E|D_{2}D_{1})=\\frac{P(D_{2}|ED_{1})P(E|D_{1})}{P(D_{2}|D_{1})}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAsu1RWg6yZn",
        "colab_type": "text"
      },
      "source": [
        "# Inferencia Bayesiana y Prior conjugado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOO9WUF-7h2S",
        "colab_type": "text"
      },
      "source": [
        "Resolvamos el siguiente ejercicio\n",
        "\n",
        "__Ejercicio__\n",
        "\n",
        "Para mantener el distanciamiento social, decidi comprar un medidor de distancias a base de laser. Segun el fabricante, la incerteza en la medicion es de 1 cm (estoy exagerando, no culpen a los laseres). En la fila del supermercado, y como estoy aburrido, observe que no estoy del todo seguro de que la persona delante mio este a 1 metro y medio de distancia: puede estar 10 centrimetros mas adelante o mas atras (se me empanian los anteojos). Dado que llevo el laser conmigo, mido 5 veces la distancia para estar seguro.\n",
        "\n",
        "Como puedo usar lo que vimos con Rodrigo para deducir la distancia?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDJfTj0u29Re",
        "colab_type": "text"
      },
      "source": [
        "__Datos__\n",
        "\n",
        "Voy a generar los datos yo. Utilizo el metodo norm.rvs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tge7Wl9X3FTf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N=5\n",
        "mu_true=1.30\n",
        "sigma=0.01\n",
        "distancias=norm.rvs(loc=mu_true,scale=sigma,size=N)\n",
        "plt.hist(distancias)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xnXvAAs6H38",
        "colab_type": "text"
      },
      "source": [
        "__Teorema de Bayes__\n",
        "\n",
        "Planteemos el problema en funcion de parametros y mediciones. Veamos que queremos deducir."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAiFP_aE6uME",
        "colab_type": "text"
      },
      "source": [
        "## Oculten esto hasta resolver el Teorema de Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmGagr8S27Hl",
        "colab_type": "text"
      },
      "source": [
        "__Verosimilitud__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrOrLmLv27E4",
        "colab_type": "text"
      },
      "source": [
        "Como argumentamos, vamos a asumir que la distribucion de los datos, es decir las mediciones de la distancia es una Gaussiana dictada por la distancia real $\\mu$ con incerteza $\\sigma$ dada por el laser. En ese caso, para una unica medicion la verosimilitud tendra la forma\n",
        "\n",
        "$p(x|\\mu,\\sigma)=\\mathcal{N}(x|\\mu,\\sigma)=\\frac{1}{\\sqrt{2\\pi\\sigma^{2}}}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}$\n",
        "\n",
        "Si tengo N mediciones independientes:\n",
        "\n",
        "$p(x_1,x_2,...,x_N|\\mu,\\sigma)=\\prod_{i=1}^{N}p(x_{i}|\\mu,\\sigma)=\\frac{1}{(2\\pi\\sigma^2)^{N/2}}e^{-\\frac{1}{2\\sigma^2}\\sum_{i=1}^{N}(x_{i}-\\mu)^2}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IqT_ez45t01",
        "colab_type": "text"
      },
      "source": [
        "__Prior__\n",
        "\n",
        "Considero como prior para la distancia real $\\mu$ una distribucion normal centrada en mi estimacion a ojo $\\mu_{0}$ y la incerteza de esa estimacion $\\sigma_{0}$.\n",
        "\n",
        "$p(\\mu|\\mu_{0},\\sigma_{0})=\\mathcal{N}(\\mu|\\mu_{0},\\sigma_{0})=\\frac{1}{\\sqrt{2\\pi\\sigma_{0}^{2}}}e^{-\\frac{(\\mu-\\mu_{0})^2}{2\\sigma_{0}^2}}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RffIMFKF9RN",
        "colab_type": "text"
      },
      "source": [
        "__Inferencia__\n",
        "\n",
        "Este prior tiene la ventaja de que es conjugado. Esto quiere decir que, viendo el __Teorema de Bayes__\n",
        "\n",
        "$p(\\mu|x_{1},x_{2},...,x_{N}, \\sigma, \\mu_0,\\sigma_0)=\\frac{\\mathcal{N}(x_1,x_2,...,x_N|\\mu,\\sigma)\\mathcal{N}(\\mu|\\mu_{0},\\sigma_{0})}{p(x_1,x_2,...,x_N|\\sigma,\\mu_0,\\sigma_0)}=\\mathcal{N}(\\mu|\\mu_N,\\sigma_N)$\n",
        "\n",
        "Donde \n",
        "\n",
        "$\\mu_N = \\frac{\\sigma^2}{\\sigma^2+N\\sigma_{0}^{2}}\\mu_{0}+\\frac{N\\sigma_{0}^2}{\\sigma^2+N\\sigma_{0}^{2}}\\mu_{ML}$\n",
        "\n",
        "$\\frac{1}{\\sigma_{N}^{2}}=\\frac{N}{\\sigma^{2}}+\\frac{1}{\\sigma_{0}^{2}}$\n",
        "\n",
        "Con $\\mu_{ML} = \\frac{1}{N}\\sum_{i=1}^{N}x_{i}$.\n",
        "\n",
        "Es decir, uno puede resolver analiticamente este problema y obtener la distribucion de probabilidad de la distancia real que incorpora las $N$ mediciones.\n",
        "\n",
        "__Mini ejercicio__\n",
        "\n",
        "Charlemos limites de $\\mu_N$ y $\\sigma_N$\n",
        "\n",
        "```\n",
        "# Esto tiene formato de código\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4RBoqgIFgj-",
        "colab_type": "text"
      },
      "source": [
        "__Implementacion__\n",
        "\n",
        "Hagamoslo de dos maneras: grafiquemos la funcion analitica y apliquemos el teorema de Bayes numericamente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1weUL5gfGe5C",
        "colab_type": "text"
      },
      "source": [
        "### Implementacion hecha por si no alcanza el tiempo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1w0qXfmGH35",
        "colab_type": "text"
      },
      "source": [
        "__Analitica__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRPt8sVjFsDf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mu_0=1.5\n",
        "sigma_0=0.1\n",
        "mu_ML=np.mean(distancias)\n",
        "nsteps=100\n",
        "mu=np.linspace(1.0,2.0,nsteps)\n",
        "bin=(mu[-1]-mu[0])/nsteps\n",
        "prior=norm(loc=mu_0,scale=sigma_0)\n",
        "plt.plot(mu,prior.pdf(mu),color='blue',label='Prior')\n",
        "\n",
        "verosimilitud_aux=list(map(lambda x: norm.pdf(x,mu,sigma*np.ones(len(mu))),distancias))\n",
        "verosimilitud=np.prod(verosimilitud_aux,axis=0)\n",
        "plt.plot(mu,verosimilitud/(bin*np.sum(verosimilitud)),color='red',label='Forma de la Verosimilitud')\n",
        "\n",
        "\n",
        "mu_N=mu_0*(sigma**2)/(N*(sigma_0)**2+sigma**2)+mu_ML*(N*sigma_0**2)/(N*(sigma_0)**2+sigma**2)\n",
        "sigma_N=np.sqrt(1/(1/sigma_0**2+N/sigma**2))\n",
        "posterior_an=norm(loc=mu_N,scale=sigma_N)\n",
        "plt.plot(mu,posterior_an.pdf(mu),color='magenta',label='Posterior Analtica')\n",
        "\n",
        "plt.xlabel('$\\mu$')\n",
        "plt.legend(loc='upper left')\n",
        "\n",
        "\n",
        "print(np.mean(posterior_an.rvs(size=nsteps)),np.sqrt(np.var(posterior_an.rvs(size=nsteps))))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pw8cQdOeGKng",
        "colab_type": "text"
      },
      "source": [
        "__Numerica__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNVZDmQAGMy0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mu_0=1.5\n",
        "sigma_0=0.1\n",
        "mu_ML=np.mean(distancias)\n",
        "nsteps=100\n",
        "mu=np.linspace(1.0,2.0,nsteps)\n",
        "bin=(mu[-1]-mu[0])/nsteps\n",
        "prior=norm(loc=mu_0,scale=sigma_0)\n",
        "plt.plot(mu,prior.pdf(mu),color='blue',label='Prior')\n",
        "\n",
        "verosimilitud_aux=list(map(lambda x: norm.pdf(x,mu,sigma*np.ones(len(mu))),distancias))\n",
        "verosimilitud=np.prod(verosimilitud_aux,axis=0)\n",
        "plt.plot(mu,verosimilitud/(bin*np.sum(verosimilitud)),color='red',label='Forma de la Verosimilitud')\n",
        "\n",
        "print((mu.shape,prior.pdf(mu).shape,verosimilitud.shape))\n",
        "evidencia=np.sum(verosimilitud*prior.pdf(mu))*bin\n",
        "posterior_num=verosimilitud*prior.pdf(mu)/evidencia\n",
        "plt.plot(mu,posterior_an.pdf(mu),color='green',label='Posterior Numerica')\n",
        "\n",
        "plt.xlabel('$\\mu$')\n",
        "plt.legend(loc='upper left')\n",
        "\n",
        "\n",
        "print(np.mean(posterior_num.rvs(size=nsteps)),np.sqrt(np.var(posterior_num.rvs(size=nsteps))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2dnEVr77SDO",
        "colab_type": "text"
      },
      "source": [
        "### Demostracion "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJG6uOVTG2kN",
        "colab_type": "text"
      },
      "source": [
        "Demostremos la propiedad del prior conjugado utilizando una unica medicion $x$. Para ese caso\n",
        "\n",
        "$p(\\mu|x,\\sigma, \\mu_0,\\sigma_0)=\\frac{1}{\\sqrt{2\\pi\\sigma^{2}}}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}\\frac{1}{\\sqrt{2\\pi\\sigma_{0}^{2}}}e^{-\\frac{(\\mu-\\mu_{0})^2}{2\\sigma_{0}^2}}\\frac{1}{p(x|\\sigma,\\mu_{0},\\sigma_{0})}$\n",
        "\n",
        "Con $p(x|\\sigma,\\mu_{0},\\sigma_{0})=\\int\\frac{1}{\\sqrt{2\\pi\\sigma^{2}}}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}\\frac{1}{\\sqrt{2\\pi\\sigma_{0}^{2}}}e^{-\\frac{(\\mu-\\mu_{0})^2}{2\\sigma_{0}^2}}d\\mu $\n",
        "\n",
        "Las constantes multiplicativas se simplifican. Ademas, puedo sacar todos los terminos que no dependan de $\\mu$ de la integral y simplificarlos. Estos son\n",
        "\n",
        "$e^{-\\frac{x^2}{2\\sigma^2}}e^{-\\frac{\\mu_{0}^2}{2\\sigma_{0}^{2}}}$\n",
        "\n",
        "Simplificando y juntando las exponenciales\n",
        "\n",
        "$p(\\mu|x,\\sigma, \\mu_0,\\sigma_0)=\\frac{e^{-[\\mu^2(\\frac{1}{2\\sigma^2}+\\frac{1}{2\\sigma_{0}^2})-2\\mu(\\frac{x}{2\\sigma^2}+\\frac{\\mu_0}{2\\sigma_{0}^{2}})]}}{\\int e^{-[\\mu^2(\\frac{1}{2\\sigma^2}+\\frac{1}{2\\sigma_{0}^2})-2\\mu(\\frac{x}{2\\sigma^2}+\\frac{\\mu_0}{2\\sigma_{0}^{2}})]}d\\mu }$\n",
        "\n",
        "Recordemos que se cumple trivialmente que $\\int p(\\mu|x,\\sigma,\\mu_0,\\sigma_0)d\\mu =1$\n",
        "\n",
        "Vemos que esto tiene forma de exponencial cuadratica en $\\mu$. Recordando la forma generica de una gaussiana:\n",
        "\n",
        "$\\mathcal{N}(\\mu|\\mu_{1},\\sigma_{1})=\\frac{e^{-\\frac{(\\mu-\\mu_{1})^2}{2\\sigma_{1}^{2}}}}{\\int e^{-\\frac{(\\mu-\\mu_{1})^2}{2\\sigma_{1}^{2}}} d\\mu}$\n",
        "\n",
        "Abriendo cuadrados obtenemos $\\mu_{1}$ y $\\sigma_{1}$ comparando termino por termino.  Noten que la expresion de $p(\\mu|x,\\sigma,\\mu_{0},\\sigma_{0})$ solo contiene terminos cuadraticos y lineales en $\\mu$. Sin embargo, el termino $e^{-\\frac{\\mu_{1}^{2}}{2\\sigma_{1}^2}}$ puede agregarse tanto al denominador como al numerador, recuperando efectivamente $\\mathcal{N}(\\mu|\\mu_1,\\sigma_1)$.\n",
        "\n",
        "Para el caso de $N$ mediciones independientes, las cuentas son analogas y pueden obtener $\\mu_{N}$ y $\\sigma_{N}$.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PE2SO115zZ9I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}