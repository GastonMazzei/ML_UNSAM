{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos Lineales - Parte 1. Regresión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Índice<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Distribución-de-los-parámetros\" data-toc-modified-id=\"Distribución-de-los-parámetros-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Distribución de los parámetros</a></span><ul class=\"toc-item\"><li><span><a href=\"#Prior-de-los-parámetros\" data-toc-modified-id=\"Prior-de-los-parámetros-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Prior de los parámetros</a></span></li><li><span><a href=\"#Máximo-a-posteriori-(MAP)\" data-toc-modified-id=\"Máximo-a-posteriori-(MAP)-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Máximo a posteriori (MAP)</a></span></li><li><span><a href=\"#Distribución-posterior\" data-toc-modified-id=\"Distribución-posterior-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Distribución posterior</a></span></li><li><span><a href=\"#¿Por-qué-distribuciones-normales?\" data-toc-modified-id=\"¿Por-qué-distribuciones-normales?-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>¿Por qué distribuciones normales?</a></span></li></ul></li><li><span><a href=\"#Distribición-predictiva\" data-toc-modified-id=\"Distribición-predictiva-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Distribición predictiva</a></span><ul class=\"toc-item\"><li><span><a href=\"#Predicciones-semi-bayesianas\" data-toc-modified-id=\"Predicciones-semi-bayesianas-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Predicciones semi-bayesianas</a></span></li><li><span><a href=\"#La-función-predictiva-posterior\" data-toc-modified-id=\"La-función-predictiva-posterior-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>La función predictiva posterior</a></span></li><li><span><a href=\"#Ejemplo\" data-toc-modified-id=\"Ejemplo-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Ejemplo</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arrancamos con una celda preparatoria, como de costumbre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"05_ModelosLineales\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"plots\", CHAPTER_ID)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "\n",
    "# Ignore useless warnings (see SciPy issue #5998)\n",
    "# import warnings\n",
    "# warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión lineal bayesiana."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta ahora, nuestro acercamiento a la regresión lineal se centró en encontrar los parámetros que minimizaban una determinada función de error.\n",
    "\n",
    "En el caso de 1) errores normales, 2) independientes, 3) con la misma varianza, vimos que esa función de error correspondía al logaritmo de la verosimilitud, y que los parámetros que encontrábamos eran estimadores de máxima verosimilitud, que tienen una serie de propiedades muy buenas.\n",
    "\n",
    "La maximización de la verosimilitud tiene un límite, sin embargo: la complejidad (y flexibilidad) del modelo no puede ser muy grande, porque si no, el modelo tiende a ajustar. Hay que *elegir*, entonces, la complejidad del modelo, teniendo en cuenta el conjunto de datos disponible. Vimos que dejar de lado un conjunto de validación (o hacer CV) puede ayudarnos a tomar esta decisión de manera criteriosa.\n",
    "\n",
    "Por otro lado, vimos que podemos modificar la función de error agregando un término de regularización, y controlar la complejidad efectiva del modelo a través de un nuevo hiperparámetro. En este caso, sin embargo, no es trivial encontrar una función de verosimilitud asociada con la función a minimizar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribución de los parámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\newcommand{\\vv}[1]{\\boldsymbol{#1}}$\n",
    "$\\newcommand{\\om}[0]{\\boldsymbol{\\omega}}$\n",
    "$\\newcommand{\\norm}[0]{\\mathcal{N}}$\n",
    "$\\newcommand{\\b}[1]{\\mathrm{\\mathbf{#1}}}$\n",
    "$\\newcommand{\\T}{^\\mathrm{T}}$\n",
    "\n",
    "En la visión bayesiana, los parámetros del modelo también tienen distribuciones de probabilidad, que nos indican nuestro grado de conocimiento del valor de ese parámetro.\n",
    "\n",
    "Para empezar con el *approach* bayesiano, lo primero que tenemos que hacer es decidir un prior para los parámetros.\n",
    "\n",
    "Pero primero, recordemos que, en general, el objetivo de la regresión es encontrar los parámetros $\\vv{\\omega}$ de la distribución *condicional* $p(t | x, \\om, \\beta)$. Desde el primer momento, hicimos una suposición <font size=5>enorme</font>:\n",
    "\n",
    "$$\n",
    "p(t | x, \\om, \\beta) = \\norm(t| y(x, \\om), \\beta^{-1})\\;\\;.\n",
    "$$\n",
    "\n",
    "Es decir, que la distribución condicional de los targets es una normal, centrada en la predicción del modelo, $y(x, \\om)$, que puede expresarse, en el caso de modelos lineales, como:\n",
    "\n",
    "$$\n",
    "y(x, \\om) = \\sum_{j=0}^M \\omega_j \\phi_j(x)\\;\\;,\n",
    "$$\n",
    "\n",
    "donde supusimos $\\phi_0(x) = 1$. Esta sumatoria puede expresarse de manera vectorial, definiendo el vector de las funciones de base, $\\boldsymbol{\\phi} = (\\phi_0, \\ldots, \\phi_M)\\T$, y el de los parámetros, $\\om = (\\omega_0, \\ldots, \\omega_M)\\T$:\n",
    "\n",
    "$$\n",
    "y(x, \\om) = \\om\\T \\boldsymbol{\\phi}(x)\\;\\;.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con todo esto, encontramos los valores de los parámetros que maximizaban la verosimilitud, $\\vv{\\om}_\\mathrm{ML}$ y $\\beta_\\mathrm{ML}$:\n",
    "\n",
    "$$\n",
    "\\om_\\mathrm{ML} = (\\boldsymbol{\\Phi}\\T \\boldsymbol{\\Phi})^{-1}\\,\\boldsymbol{\\Phi}\\T\\,\\b{t}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{1}{\\beta_{ML}} = \\frac{1}{N}\\sum_{i=1}^N\\left\\{y(x_i, \\boldsymbol{\\omega}_{ML}) - t_i\\right\\}^2\\;\\;,\n",
    "$$\n",
    "\n",
    "donde $\\boldsymbol{\\Phi}$ es la *matriz de diseño*, cuya fila $i$-ésima es simplemente $\\boldsymbol{\\phi}(x_i)$.\n",
    "\n",
    "En la filosofía bayesiana, esto es solo parte de la historia. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prior de los parámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fijemos un prior para los parámetros. Como la verosimilitud es normal, una elección natural (y simple) es elegir priors normales para $\\om$:\n",
    "\n",
    "$$\n",
    "p(\\om | \\gamma) = \\norm(\\om | 0, \\gamma^{-1}\\mathrm{\\mathbf{I}})\\;\\;,\n",
    "$$\n",
    "que depende de un único hiperparámetro escalar, $\\gamma$ que define la precisión de los parámetros (la inversa de la varianza.\n",
    "\n",
    "En el ejemplo del ajuste polinomial, con grado $M$ (en realidad, siempre que haya $M$ funciones de base más un parámetro de sesgo $\\omega_0$) esto es:\n",
    "\n",
    "$$\n",
    "p(\\om | \\gamma) = \\left(\\frac{\\gamma}{2\\pi}\\right)^{(M+1)/2} \\exp{\\left\\{-\\frac{\\gamma}{2}\\om^T\\om\\right\\}}\\;\\;.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Máximo a posteriori (MAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para encontrar la distribución posterior de los parámetros, usamos el teorema de Bayes.\n",
    "\n",
    "$$\n",
    "p(\\om | \\b{t}, \\beta, \\gamma) = \\frac{p(\\b{t} | \\om, \\beta, \\gamma)\\,p(\\om | \\gamma)}{p(\\b{t} | \\beta, \\gamma)}\\;\\;,\n",
    "$$ \n",
    "\n",
    "donde escribí de forma explícita todos los elementos condicionales (los datos, $\\b{t}$ --recordemos que cada $t_i$ siempre viene asociado con un $x_i$, que ya no escribo para no abundar--, y los hiperparámetros $\\beta$ y $\\gamma$). Recuerde que el numerador es una constante con respecto a $\\om$, de manera que podemos obviarla para buscar la maximización de la posterior.\n",
    "\n",
    "Entonces, tenemos\n",
    "\n",
    "$$\n",
    "p(\\om | \\b{t}, \\beta, \\gamma) \\propto p(\\b{t} | \\om, \\beta, \\gamma)\\,p(\\om | \\gamma)\\;\\;.\n",
    "$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este punto ponemos nuestras decisiones de prior y de verosimilitud:\n",
    "\n",
    "$$\n",
    "p(\\om | \\b{t}, \\beta, \\gamma) \\propto \\prod_{i=1}^N \\norm(t_i| y(x_i, \\om), \\beta^{-1})\\; \\left(\\frac{\\gamma}{2\\pi}\\right)^{(M+1)/2} \\exp{\\left\\{-\\frac{\\gamma}{2}\\om^T\\om\\right\\}}\\;\\;.\n",
    "$$\n",
    "\n",
    "Como de costumbre, es más fácil maximizar el logaritmo de la posterior:\n",
    "\n",
    "$$\n",
    "\\ln p(\\om | \\b{t}, \\beta, \\gamma) = -\\frac{\\beta}{2}\\sum_{i=1}^N \\left\\{t_i - \\om\\T\\boldsymbol{\\phi}(x_i)\\right\\}^2 - \\frac{\\gamma}{2}\\om\\T\\om + \\text{const}\\;\\;,\n",
    "$$\n",
    "\n",
    "que es equivalente a la función de error de la regresión *ridge*, con $\\lambda = \\gamma/\\beta$. O sea, que (con esta elección de verosimilitud y prior), encontramos naturalmente una regresión regularizada. Entonces, siguiendo la misma línea de razonamiento que en su momento, obtenemos que el vector de parámetros que maximiza el valor de la distribución posterior es:\n",
    "\n",
    "$$\n",
    "\\om_\\mathrm{MAP} = \\left(\\frac{\\gamma}{\\beta}\\mathrm{\\mathbf{I}} + \\boldsymbol{\\Phi}\\T \\boldsymbol{\\Phi}\\right)^{-1}\\,\\boldsymbol{\\Phi}\\T\\,\\b{t}\n",
    "$$\n",
    "\n",
    "***\n",
    "**Una nota**. Otra vez vemos que el problema del sobreajuste está íntimamente vinculado con la búsqueda de maximizar la verosimilitud. Es lo mismo que pasaba con la moneda: si hacemos tres tiradas y sacamos caras en todas, podemos calcular, via ML, que $\\mu=1$, y el conjunto de entrenamiento (tres caras) estará perfectamente ajustado, pero el modelo va a fallar de forma miserable con datos que no haya visto antes. En cambio, si vemos la posterior de $\\mu$, encontramos que existe posibilidad de obtener ceca en tiradas ulteriores.\n",
    "***\n",
    "\n",
    "Con otras elecciones de prior, podemos llegar a Lasso u otro tipo de regularizaciones (ver ec. 3.56 del [Bishop](https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribución posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya tenemos el valor que maximiza la posterior. Pero, ¿cómo es la distribución posterior completa? \n",
    "\n",
    "Para encontrar esto, usamos el hecho de que la distribución normal es el prior conjugado para una verosimilitud normal (si suponemos conocida la matriz de precisión, $\\beta$). Por lo tanto, la posterior también será una distribución multinormal.\n",
    "\n",
    "$$\n",
    "p(\\om | \\b{t}, \\beta, \\gamma) = \\norm(\\om | \\mathbf{m}_N, \\mathbf{S}_N)\\;\\;,\n",
    "$$\n",
    "\n",
    "donde $\\mathbf{m}_N$ y $\\mathbf{S}_N$ son el vector de valores medios y la matriz de covarianza, respectivamente, y el subíndice hace alusión al tamaño de los datos tenidos en cuenta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el prior que elegimos arriba, \n",
    "\n",
    "$$\n",
    "p(\\om | \\gamma) = \\norm(\\om | \\mathbf{0}, \\gamma^{-1} \\mathbf{I}) = \\left(\\frac{\\gamma}{2\\pi}\\right)^{(M+1)/2} \\exp{\\left\\{-\\frac{\\gamma}{2}\\om^T\\om\\right\\}}\\;\\;,\n",
    "$$\n",
    "\n",
    "obtenemos, usando propiedades de la distribución normal, que:\n",
    "\n",
    "$$\n",
    "\\boxed{\\begin{array}{lll}\n",
    "\\mathbf{m}_N &=& \\beta\\;\\mathbf{S}_N \\boldsymbol{\\Phi}\\T \\b{t}\\\\\n",
    "\\mathbf{S}^{-1}_N &=& \\gamma\\;\\mathbf{I} + \\beta\\;\\boldsymbol{\\Phi}\\T \\boldsymbol{\\Phi}\\;\\;.\n",
    "\\end{array}}\n",
    "$$\n",
    "\n",
    "Noten que si metemos el resultado de $\\mathbf{S}_N$ en al ecuación de la media, recuperamos la ecuación de arriba para $\\om_\\mathrm{MAP}$. Esto es razonable, como la normal es simétrica, el valor que maximiza la posterior es también el valor medio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En un ejercicio vamos a ver cómo pueden usarse estas fórmulas para un aprendizaje secuencial de la posterior. Acá, veamos cómo se compara lo que sale de acá con los estimadores de máxima verosimilitud que vimos para la ordenada al origen ($\\omega_0$) y pendiente ($\\omega_1$) de una regresión lineal hace unas clases (la visión frecuentista).\n",
    "\n",
    "Si tenemos un modelo lineal, $y(x, \\om) = \\omega_0 + \\omega_1\\,x$, la matriz de diseño y su transpuesta son\n",
    "\n",
    "$$\n",
    "\\boldsymbol{\\Phi} = \\begin{pmatrix}\n",
    "                    1 & x_1\\\\\n",
    "                    1 & x_2\\\\\n",
    "                    \\vdots& \\vdots\\\\\n",
    "                    1 & x_N\\\\\\end{pmatrix}\n",
    "$$                    \n",
    "\n",
    "$$\n",
    "\\boldsymbol{\\Phi}^T = \\begin{pmatrix}\n",
    "                    1 & 1 & \\cdots & 1\\\\\n",
    "                    x_1 & x_2 & \\cdots & x_N\\\\\n",
    "   \\end{pmatrix}\\;\\;.\n",
    "$$\n",
    "\n",
    "Entonces, la matriz de precisión queda\n",
    "\n",
    "$$\n",
    "\\boldsymbol{S}_N^{-1} = \\beta \\begin{pmatrix}N + \\gamma/\\beta & N\\bar{x}\\\\\n",
    "                                       N\\bar{x} & \\sum_i x_i^2 + \\gamma/\\beta\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "si tenemos un prior que se va ensanchando hasta el infinito: es decir, que no tenemos prior, y en términos matemáticos, $\\gamma \\rightarrow 0$, queda\n",
    "\n",
    "$$\n",
    "\\boldsymbol{S}_N^{-1} = N\\beta \\begin{pmatrix}1 & \\bar{x}\\\\\n",
    "                                       \\bar{x} & \\frac{1}{N}\\sum_i x_i^2\n",
    "\\end{pmatrix}\\;\\;,\n",
    "$$\n",
    "\n",
    "que es la misma expresión que teníamos para la covarianza de los estimadores de ML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pensemos ahora en prior más general (pero siempre normal):\n",
    "\n",
    "$$\n",
    "p(\\om | \\mathbf{m}_0, \\mathbf{S}_0) = \\norm(\\om | \\mathbf{m}_0, \\mathbf{S}_0)\\;\\;,\n",
    "$$\n",
    "\n",
    "donde ahora la matiz de covarianza es general. Entre otras cosas, esto permite acomodar constantes de regularización diferentes para cada parámetro, que fue una pregunta de hace unas clases; además, podemos pensar en una matriz no diagonal, mucho más flexible. \n",
    "\n",
    "Como sea, el valor medio y matriz de precisión de la posterior en este caso es:\n",
    "\n",
    "$$\n",
    "\\boxed{\\begin{array}{lll}\n",
    "\\mathbf{m}_N &=& \\mathbf{S}_N\\; \\left(\\mathbf{S}^{-1}_0 \\mathbf{m}_0 + \\beta\\;\\boldsymbol{\\Phi}\\T \\b{t}\\right)\\\\\n",
    "\\mathbf{S}^{-1}_N &=& \\mathbf{S}^{-1}_0 + \\beta\\;\\boldsymbol{\\Phi}\\T \\boldsymbol{\\Phi}\\;\\;.\n",
    "\\end{array}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esto, tenemos una descripción completa de la distribución del vector de parámetros $\\om\\T = (\\omega_0, \\ldots, \\omega_M)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Por qué distribuciones normales?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A esta altura del partido, es lícito preguntarse por qué estamos insistiendo tanto con las distribuciones normales, y dándole un rol tan central.\n",
    "\n",
    "Las razones son múltiples, pero una de las más potentes es posiblemente el Teorema Central del Límite (ver  [el notebook correspondiente](06a_TeoremaCentralLimite.ipynb)) y las diapositivas de la clase de hoy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribición predictiva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hace un tiempo hablamos de la prevalencia de la visión predictiva vs. la visión inferencista o explicativa. De forma que todo lo de arriba, referido a los parámetros solo es una parte de la visión bayesiana, relacionada con cómo encontrar los mejores parámetros y su distribución.\n",
    "\n",
    "Si queremos hacer predicciones, tenemos dos caminos: la forma semi-bayesiana, en la que fijamos los valores de los parámetros al valor MAP, o la forma *fully bayesian* en la que usamos la regla del producto y de la suma de forma sistemática."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicciones semi-bayesianas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este approach, la predicción consiste en tomar la verosimilitud y evaluarla en el valor MAP del vector de parámetros $\\om$:\n",
    "\n",
    "$$\n",
    "p(t | x, \\om_\\mathrm{MAP}, \\beta) = \\norm(t| y(x, \\om_\\mathrm{MAP}), \\beta^{-1})\\;\\;,\n",
    "$$\n",
    "\n",
    "donde, recordemos, suponemos que $\\beta$ es conocida (ya vamos a ver cómo se puede *inferir* en esta visión). Con esta distribución, las predicciones sobre $t$ tienen naturaleza probabilística, como queda más o menos claro en esta figura del Bishop:\n",
    "\n",
    "<img width=400px src=\"images/Figure1.16.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La función predictiva posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin embargo, haber fijado el parámetro $\\om$ a un valor, cuando en realidad contamos con toda su distribución (la posterior, $p(\\om | \\b{t})$) no es totalmente bayesiano. Mi abuela decía que fijar parámetros hace llorar al niño Bayes.\n",
    "\n",
    "Entonces, ¿cómo hacemos para tener en cuenta *toda* la información disponible a la hora de hacer predicciones? ¿Cómo hacemos para ser completamente bayesianos.\n",
    "\n",
    "Primero, pensemos qué es lo que queremos realmente. \n",
    "\n",
    "***\n",
    "**Pregunta**: ¿Alguna idea? ¿Qué es predecir?\n",
    "\n",
    "¿Les parece razonable pensar que queremos saber cómo será la distribución de una nueva medición $t^\\prime$, pero una vez que hayamos considerado los datos ya obtenidos, $\\b{t}$?\n",
    "\n",
    "Y si es así, ¿cómo escribo eso? ¡¿Y cómo lo calculo?!\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo, entonces, es encontrar\n",
    "\n",
    "$$\n",
    "p(t^\\prime | \\b{t}, \\beta, \\gamma)\\;\\;,\n",
    "$$\n",
    "\n",
    "donde condicioné a los valores de los hiperparámetros. Mal no puede hacer.\n",
    "\n",
    "Así escrito esto no lo sé calcular, pero podemos escribir la distribución conjunta con una variable extra, y usar la regla de la suma para marginalizar:\n",
    "\n",
    "$$\n",
    "p(t^\\prime | \\b{t}, \\beta, \\gamma) = \\int p(t^\\prime, \\om | \\b{t}, \\beta, \\gamma)\\;\\mathrm{d}\\om\\;\\;.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En otras palabras, marginalizo sobre $\\om$. Ahora, el integrando puedo expresarlo de una manera más simpática, usando la regla del producto:\n",
    "\n",
    "$$\n",
    "p(t^\\prime, \\om | \\b{t}, \\beta, \\gamma) = p(t^\\prime | \\om, \\b{t}, \\beta, \\gamma)\\;p(\\om | \\b{t}, \\beta, \\gamma)\\;\\;.\n",
    "$$\n",
    "\n",
    "Veamos los dos términos. En el primero, como estamos condicionando con respecto a $\\om$, la distribución de $t^\\prime$ se vuelve independiente de $\\b{t}$ (estamos usando fuertemente la hipótesis de independencia). Entonces, el primer término es $p(t^\\prime | \\om, \\beta, \\gamma)$, donde reconocemos a la verosimilitud de un dato (es independiente de $\\gamma$):\n",
    "\n",
    "$$\n",
    "p(t^\\prime | \\om, \\beta) = \\norm(t^\\prime| y(x, \\om), \\beta^{-1})\\;\\;.\n",
    "$$\n",
    "\n",
    "El segundo término, $p(\\om | \\b{t}, \\beta, \\gamma)$ no es ni más ni menos que la posterior del vector de parámetros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos entonces interpretar a la integral de arriba como el valor medio de la verosimilitud con respecto a la distribución posterior de $\\om$\n",
    "\n",
    "***\n",
    "**Recordatorio**. El valor medio de una función $f(x)$ con respecto a la función de distribución $p(x)$ es\n",
    "\n",
    "$$\n",
    "<f(x)>_{p(x)} = \\int f(x)\\,p(x)\\;\\mathrm{d}x\\;\\;.\n",
    "$$\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gracias a algunas propiedades adicionales de las distribuiones normales, podemos resolver analíticamente la integral que da lugar a la posterior predictiva:\n",
    "\n",
    "$$\n",
    "p(t^\\prime | \\b{t}, \\beta, \\gamma) = \\norm(t^\\prime | \\mathbf{m}_N\\T \\boldsymbol{\\phi}(x), \\sigma_N^2)\\;\\;,\n",
    "$$\n",
    "\n",
    "donde la variaza es\n",
    "$$\n",
    "\\sigma_N^2 = \\frac{1}{\\beta} + \\boldsymbol{\\phi}(x)\\T \\mathbf{S}_N \\boldsymbol{\\phi}(x)\\;\\;,\n",
    "$$\n",
    "que consiste en una contribución debida a la incertidumbre en los parámetros, y otra que viene de la incerteza de los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos esto en acción con nuestro ya conocido dataset sinusoidal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array para plotear\n",
    "xx = np.linspace(0, 1, 100).reshape([-1, 1])\n",
    "\n",
    "def plot_data_sine(x, t, ax=None):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    ax.plot(x, t, 'ob', mfc='None', ms=10)\n",
    "    ax.plot(xx, np.sin(2*np.pi * xx), 'g-', lw=2, alpha=0.7, label='Ground Truth')\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('t')\n",
    "    ax.legend(loc=0)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123456)\n",
    "\n",
    "# Nuevo set de datos (esta vez, hago dos copias)\n",
    "x_ = np.random.rand(100, 1)\n",
    "# x_ = np.array([0.2, 0.8]).reshape((-1, 1))\n",
    "\n",
    "t_ = np.sin(2*np.pi*x_) + np.random.randn(len(x_), 1) * 0.3\n",
    "\n",
    "plot_data_sine(x_, t_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fijemos los hiperparámetros\n",
    "beta = 1/0.3\n",
    "gamma = 1e5 / 0.3 # gamma/beta = lambda \n",
    "\n",
    "# Number of points to use\n",
    "n = 10\n",
    "ii = np.arange(len(x_))\n",
    "np.random.shuffle(ii)\n",
    "ii = ii[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Features polinomiales\n",
    "\n",
    "# Escribamos la matriz de diseño para polinomios de grado 5\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "polfeat = PolynomialFeatures(degree=4)\n",
    "phi = polfeat.fit_transform(x_[ii])\n",
    "\n",
    "# Necesito también la \"matriz de diseño\" del vector xx\n",
    "phi_ = polfeat.transform(xx)\n",
    "\n",
    "print('Dimensiones de la matriz de diseño: {}'.format(phi.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Gaussian features instead\n",
    "\n",
    "mu = np.linspace(0.1, 0.9, 20)\n",
    "s2 = 0.1\n",
    "phi = np.ones((len(x_[ii]), len(mu)+1))\n",
    "phi_ = np.ones((len(xx), len(mu)+1))\n",
    "\n",
    "for j, m in enumerate(mu):\n",
    "    phi[:, j+1] = np.exp(-(x_[ii].flatten() - m)**2 / s2)\n",
    "    phi_[:, j+1] = np.exp(-(xx.flatten() - m)**2 / s2)\n",
    "    \n",
    "print('Dimensiones de la matriz de diseño: {}'.format(phi.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordamos:\n",
    "\n",
    "$$\n",
    "\\boxed{\\begin{array}{lll}\n",
    "\\mathbf{m}_N &=& \\beta\\;\\mathbf{S}_N \\boldsymbol{\\Phi}\\T \\b{t}\\\\\n",
    "\\mathbf{S}^{-1}_N &=& \\gamma\\;\\mathbf{I} + \\beta\\;\\boldsymbol{\\Phi}\\T \\boldsymbol{\\Phi}\\;\\;.\n",
    "\\end{array}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribamos la ecuación para la inversa de la covarianza del posterior\n",
    "sn_inv = gamma + beta * np.dot(phi.T, phi)\n",
    "\n",
    "# Calculemos phiT t\n",
    "tt_ = np.dot(phi.T, t_[ii])\n",
    "\n",
    "# Y ahora usemos solve para resolver la ecuación sn_inv * x = tt_ --> x = sn * tt_\n",
    "m_n = beta * np.linalg.solve(sn_inv, tt_)\n",
    "\n",
    "print('Los valores medios de la posterior de los parámetros son: \\n{}'.format(m_n.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos plotear la predicción semi-bayesiana\n",
    "y = np.dot(phi_, m_n)\n",
    "\n",
    "plot_data_sine(x_[ii], t_[ii])\n",
    "plt.plot(xx, y, '-r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encontremos ahora los parámetros de la posterior predictiva\n",
    "\n",
    "$$\n",
    "p(t^\\prime | \\b{t}, \\beta, \\gamma) = \\norm(t^\\prime | \\mathbf{m}_N\\T \\boldsymbol{\\phi}(x), \\sigma_N^2)\\;\\;,\n",
    "$$\n",
    "\n",
    "donde la variaza es\n",
    "$$\n",
    "\\sigma_N^2 = \\frac{1}{\\beta} + \\boldsymbol{\\phi}(x)\\T \\mathbf{S}_N \\boldsymbol{\\phi}(x)\\;\\;,\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Busco la media en los 100 puntos que voy a usar para plotear\n",
    "# El vactor phi es la transpuesta de la matriz de diseño\n",
    "mean = np.dot(m_n.T, phi_.T)\n",
    "sigma2 = np.dot(np.dot(phi_, np.linalg.inv(sn_inv)), phi_.T) + 1/beta\n",
    "\n",
    "# Me quedo solo con la diagonal para los errores puntuales\n",
    "err = np.sqrt(np.diag(sigma2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_sine(x_[ii], t_[ii])\n",
    "\n",
    "ax = plt.gca()\n",
    "plt.fill_between(xx.flatten(), mean.flatten() + err, mean.flatten() - err, color='LightBlue', alpha=0.3)\n",
    "ax.set_ylim(-3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# También podemos obtener muestras de la multinormal\n",
    "import scipy.stats as st\n",
    "X = np.random.multivariate_normal(mean.flatten(), sigma2, 10)\n",
    "\n",
    "plot_data_sine(x_[ii], t_[ii])\n",
    "\n",
    "for pp in X:\n",
    "    plt.plot(xx.flatten(), pp, color='r', alpha=0.2, lw=3)\n",
    "    \n",
    "ax = plt.gca()\n",
    "ax.set_ylim(-3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "nav_menu": {
   "height": "279px",
   "width": "309px"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Índice",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "239px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
