{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos Lineales - Parte 1. Regresión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"05_ModelosLineales\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"plots\", CHAPTER_ID)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "\n",
    "# Ignore useless warnings (see SciPy issue #5998)\n",
    "# import warnings\n",
    "# warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión lineal (univariada)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vuelve a llamar Alex. Está agradecido. Pudo impresionar a su jefe gracias a lo que le mandamos de Random Forests, Neural Networks, etc. Lo nombraron *Chief Artificial Intelligence Officer*, a cargo de departamento de AI de la inmobiliaria. Pero está de vuelta en problemas (si no, creo que no llamaría). \n",
    "\n",
    "Resulta que hace un par de fin de semanas, el jefe de Alex estaba jugando al golf con otros dueños de inmobiliarias, y se mandó la parte con su recientemente creado departamento de Inteligencia Artificial, y les contó todo lo que habían logrado (gracias a nosotrxs) con respecto a la predicción de precios de casas en distritos de California. Pero se vio en un brete cuando uno de sus colegas le pidió alguna explicación respecto al funcionamiento de la predicción. ¿Qué variables son las más importantes? ¿Cómo hace la predicción?\n",
    "\n",
    "El lunes siguiente, el jefe volvió a la inmobiliaria y entró precipitadamente en la oficina de Alex para pedirle que arme un equipo que pudiera darle algún sentido a las predicciones que habían logrado antes. Le dio permiso para contratar a una persona. Alex está contento porque logró meter a su novia, Brenda, como *Senior Parameter Explorer*, pero tienen que producir algún modelo que sea más fácil de entender para el jefe, sobre todo para que no se deschave que Brenda en realidad estudio diseño gráfico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volvamos a leer los datos de California\n",
    "HOUSING_PATH = os.path.join(\".\", \"datasets\", \"housing\")\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "    \n",
    "    import tarfile\n",
    "\n",
    "    DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/IAI-UNSAM/ML_UNSAM/master/\"\n",
    "    HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
    "\n",
    "    !mkdir -p ./datasets/housing\n",
    "\n",
    "    def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
    "        os.makedirs(housing_path, exist_ok=True)\n",
    "        tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
    "        #urllib.request.urlretrieve(housing_url, tgz_path)\n",
    "        !wget https://raw.githubusercontent.com/IAI-UNSAM/ML_UNSAM/master/datasets/housing/housing.tgz -P {housing_path}\n",
    "        housing_tgz = tarfile.open(tgz_path)\n",
    "        housing_tgz.extractall(path=housing_path)\n",
    "        housing_tgz.close()\n",
    "    \n",
    "    # Corramos la función\n",
    "    fetch_housing_data()\n",
    "    \n",
    "def load_housing_data(housing_path=HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "housing = load_housing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coeficiente de Pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = housing.corr()\n",
    "corr_matrix['median_house_value'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a quedarnos solo con la mediana del ingreso y el valor de las casas.\n",
    "x = housing.median_income\n",
    "y = housing.median_house_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora nos podemos preguntar de dónde sale ese valor de 0.688. Ya lo mencionamos, pero ahora que sabemos algo más de distribuciones, podemos volver a verlo.\n",
    "\n",
    "Si usamos la siguiente notación:\n",
    "\n",
    "$$\n",
    "\\begin{array}{lll}\n",
    "\\mu_X &=& \\mathbb{E}(X)\\\\\n",
    "\\sigma^2_X &=& \\mathbb{E}\\left[(X - \\mathbb{E}(X))^2\\right] = \\mathrm{var}(X)\\;\\;,\n",
    "\\end{array}\n",
    "$$\n",
    "el coeficiente de correlación se define como \n",
    "\n",
    "$$\n",
    "\\rho_{XY} = \\mathbb{E}\\left[\\left(\\frac{X - \\mu_X}{\\sigma_X}\\right)\\left(\\frac{Y - \\mu_Y}{\\sigma_Y}\\right)\\right]\\;\\;.\n",
    "$$\n",
    "\n",
    "El valor de expectación $\\mathbb{E}$ lo definimos para las distribuciones hace unas clases. Para el caso continuo:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}(X) = \\int x f_X(x) \\mathrm{d}x\\;\\;.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora bien, ¿qué pasa si no conocemos, como ahora, $f_X$? ¿Qué pasa si solo tenemos una muestra de esa distribución?\n",
    "\n",
    "Entonces, tenemos que usar los datos para *estimar* el valor esperado, $\\mathbb{E}(X)$. Para eso, formamos un *estadístico* (*statistic*, en singular, en inglés). Es decir, una función de los datos.\n",
    "\n",
    "$$\n",
    "\\bar{X} = \\frac{1}{N}\\sum_{i=1}^N x_i\\;\\;.\n",
    "$$\n",
    "\n",
    "Cuando un estadístico se usa para aproximar el valor de una característica poblacional no conocido, se lo llama un *estimador*. En este caso el estadístico $\\bar{X}$ es un *estimador* del valor de expectación de la distribución, y a veces vamos a usar la notación:\n",
    "\n",
    "$$\n",
    "\\hat{\\mu_X} = \\bar{X}\\;\\;.\n",
    "$$\n",
    "\n",
    "También tenemos *estimadores* de la varianza y de la covarianza:\n",
    "\n",
    "$$\n",
    "\\hat{\\sigma}_X^2 = \\frac{1}{N - 1}\\sum_{i=1}^N (x_i - \\bar{X})^2\\;\\;,\n",
    "$$\n",
    "y\n",
    "$$\n",
    "\\hat{\\mathrm{cov}}_{XY} = \\frac{1}{N - 1}\\sum_{i=1}^N (x_i - \\bar{X})(y_i - \\bar{Y})\\;\\;.\n",
    "$$\n",
    "\n",
    "Con todo esto, podemos calcular un estimador del coeficiente de correlación:\n",
    "\n",
    "$$\n",
    "\\hat{\\rho_{XY}} = r = \\frac{\\hat{\\mathrm{cov}}_{XY}}{\\hat{\\sigma}_X \\hat{\\sigma}_Y}\\;\\;,\n",
    "$$\n",
    "que se conoce como el *coeficiente de correlación de Pearson*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos los estimadores de los valores medios\n",
    "Xbar = np.sum(x)/len(x)\n",
    "Ybar = np.sum(y)/len(y)\n",
    "\n",
    "# Calculamos los estimadores de los desvíos estándar (es decir, sqrt(cov))\n",
    "sigmaX = np.sqrt(np.sum((x - Xbar)**2) / (len(x) - 1))\n",
    "sigmaY = np.sqrt(np.sum((y - Ybar)**2) / (len(y) - 1))\n",
    "\n",
    "covXY = np.sum((x - Xbar) * (y - Ybar)) / (len(x) - 1)\n",
    "\n",
    "# Coeficiente de Pearson\n",
    "r = covXY / (sigmaX * sigmaY)\n",
    "\n",
    "print('El coeficiente de Pearson es: {:.3f}'.format(r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En `numpy` tenemos funciones y métodos que hacen esto: `np.mean`, `np.std`, `np.cov`, `np.corrcoef`.\n",
    "\n",
    "De ahora en más, usen esas implementaciones, porque en el fondo, `numpy` corre código en C y es mucho más rápido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix['median_house_value'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El coeficiente de correlación toma valores $-1 < \\rho < 1$, donde -1 indica una anticorrelación perfecta, y 1 indica una correlación perfecta.\n",
    "\n",
    "El estimador, $r$, es muy sensible a puntos aberrantes (*outliers*), por lo que hay que mirar un poco los datos antes de calcular los coeficientes y ya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, y, '.', alpha=0.1)\n",
    "plt.xlabel('Mediana del ingreso por distrito')\n",
    "plt.ylabel('Mediana del precio de la casa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veamos como cambia $r$ si sacamos los distritos con precios que saturan\n",
    "i = y < np.max(y)\n",
    "\n",
    "plt.plot(x[i], y[i], '.', alpha=0.1)\n",
    "plt.xlabel('Mediana del ingreso por distrito')\n",
    "plt.ylabel('Mediana del precio de la casa')\n",
    "\n",
    "\n",
    "r = np.corrcoef(x[i], y[i])[0, 1]\n",
    "print('El coeficiente de Pearson, con datos corregidos, es: {:.3f}'.format(r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Claro. Los puntos saturados, arriba a la derecha ayudan mucho a aumentar $r$ de forma espúrea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo lineal sencillo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El ingreso no es una variable ideal para determinar el precio de una casa, pero es lo mejor que tenemos, de manera individual. ¿Qué modelo podemos proponerles?\n",
    "\n",
    "Brenda recordó algo de algunas clases de matemática que tuvo en la carrera y pensó que podía armar un modelo que tuviera esta pinta:\n",
    "\n",
    "$$\n",
    "y = a * x + b\\;\\;,\n",
    "$$\n",
    "es decir, una relación lineal entre ambas variables. En este tipo de modelo, la variable $x$ se conoce con el nombre de variable predictora. Este modelo tiene dos *parámetros*: $a$ y $b$, la pendiente y ordenada al origen, respectivamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brenda encuentra en sus apuntes viejos una expresión para *ajustar* los parámetros:\n",
    "\n",
    "$$\n",
    "\\begin{array}{lll}\n",
    "\\hat{a} &=& \\sum_{i=0}^N (x_i - \\bar{X}) (y_i - \\bar{Y}) \\left[\\sum_{i=0}^N (x_i - \\bar{X})^2\\right]^{-1}\\\\\n",
    "\\hat{b} &=& \\bar{Y} - \\hat{a}\\bar{X}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Comparando con las ecuaciones de arriba, vemos que\n",
    "\n",
    "$$\n",
    "\\hat{a} = \\frac{\\hat{\\mathrm{cov}}_{XY}}{\\hat{\\mathrm{var}}(X)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculemos\n",
    "ahat = np.cov(x[i], y[i])[0,1] / np.var(x[i])\n",
    "bhat = np.mean(y[i]) - ahat * np.mean(x[i])\n",
    "\n",
    "print('Los ajustes dan')\n",
    "print('a = {:.3f}'.format(ahat))\n",
    "print('b = {:.3f}'.format(bhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x[i], y[i], '.', alpha=0.1)\n",
    "\n",
    "xx = np.linspace(x[i].min(), x[i].max(), 3)\n",
    "plt.plot(xx, xx * ahat + bhat, 'r-')\n",
    "plt.xlabel('Mediana del ingreso por distrito')\n",
    "plt.ylabel('Mediana del precio de la casa [$]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos ver los residuos, y calcular su dispersión\n",
    "res = y[i] - (ahat * x[i] - bhat)\n",
    "plt.plot(x[i], res, '.', alpha=0.1)\n",
    "plt.axhline(0, color='0.5', ls=':')\n",
    "\n",
    "print('Los residuos tienen una dispersión de $ {:.3f}'.format(res.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pregunta**\n",
    "\n",
    "- ¿Estamos contentos con el ajuste? ¿Por qué?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿De dónde viene la fórmula de regresión lineal? (o ¿qué condiciones se tienen que cumplir para que la cosa funcione?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formalizando un poco más la cosa, podemos recordar que habíamos dicho que un modelo podía escribirse:\n",
    "\n",
    "$$\n",
    "y_i = m_i + \\epsilon_i\\;\\;,\n",
    "$$\n",
    "donde $\\epsilon_i$ es el término de error.\n",
    "\n",
    "De ahora en más, vamos a llamar:\n",
    "* $t_i$ a los valores de $Y$ que queremos reproducir,\n",
    "* $y(x, \\omega)$ al modelo, que dependerá de una vector de parámetros $\\boldsymbol{\\omega}$.\n",
    "\n",
    "En este caso, estamos tomando, $y(x, \\boldsymbol{\\omega}) = \\omega_0 + \\omega_1 * x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En general, es más conveniente usar el logaritmo de la verosimilitud. Como el logaritmo es una función creciente, el máximo de la verosimilitud coincide con el máximo de su logaritmo.\n",
    "\n",
    "En este caso, obtenemos:\n",
    "\n",
    "$$\n",
    "\\ln p(\\boldsymbol{t} | \\mathbf{x}, \\boldsymbol{\\omega}, \\beta) = -\\frac{\\beta}{2} \\sum_{i=1}^{N} \\left\\{\\left(y(x_i, \\boldsymbol{\\omega}) - t_i\\right)^2\\right\\} + \\frac{N}{2}\\ln\\beta - \\frac{N}{2}\\ln 2\\pi\\;\\;.\n",
    "$$\n",
    "\n",
    "Como los últimos dos términos son constantes con respecto a los parámetros, podemos obviarlos a la hora de maximizar la verosimilitud. La tarea es, entonces, equivalente a minimizar:\n",
    "\n",
    "$$\n",
    "E(\\boldsymbol{\\omega}) = \\frac{1}{2} \\sum_{i=1}^{N} \\left\\{y(x_i, \\boldsymbol{\\omega}) - t_i\\right\\}^2\\;\\;,\n",
    "$$\n",
    "que se conoce como *error cuadrático medio*.\n",
    "\n",
    "Muchas veces, es más simpático tener una función de error que tenga las mismas unidades que los datos. Por eso, definimos la *raíz del error cuadrático medio* (*root-mean-square error*, o *RMS*):\n",
    "\n",
    "$$\n",
    "E_{RMS} = \\sqrt{2 * E(\\boldsymbol{\\omega})/N}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "**Ejercicio**\n",
    "\n",
    "* Mostrar usando la expresión del error cuadrático medio, y el modelo lineal, que los valores de los parámetros $a$ y $b$ que maximizan la verosimilitud son los que aparecen arriba.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificación de las hipótesis\n",
    "\n",
    "Volvamos al caso de California y estudiemos con más detalle lo que pasa con los residuos.\n",
    "\n",
    "En primer lugar, podemos calcular el error cuadrático medio (y su raíz) para el ajuste que hicimos arriba?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = 0.5 * np.sum(res**2)\n",
    "\n",
    "print('El error cuadrático medio es {:.3f}'.format(E))\n",
    "print('El root-mean-square error es {:.3f}'.format(np.sqrt(2 * E / len(x[i]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Pregunta**\n",
    "\n",
    "* ¿Cómo se les ocurre que podemos estudiar el cumplimiento de las hipótesis?\n",
    "***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veamos la distribución de los residuos\n",
    "a = plt.hist(res, 100, density=True)\n",
    "\n",
    "# Podemos graficar una Gaussiana encima\n",
    "# Vamos a plotear la _mejor_\n",
    "xx = np.linspace(res.min(), res.max(), 100)\n",
    "plt.plot(xx, st.norm.pdf(xx, res.mean(), res.std()), '-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "st.probplot((res - res.mean())/res.std(), plot=plt.gca())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.probplot(st.norm.rvs(0, 1, size=1000), plot=plt.gca())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión lineal con datos sintéticos (o el fin de la era de inferencia)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Regresión lineal multivariada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Regresión polinomial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Sobreajuste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Regularización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "nav_menu": {
   "height": "279px",
   "width": "309px"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
